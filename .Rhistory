p <- ggplot(df, aes(x = !!sym(col))) +
geom_histogram(fill = "blue", color = "black") +
labs(title = paste("Distribution of", col))
}
plots[[col]] <- p
}
grid.arrange(grobs = plots, ncol = 2)
}
plot_dist(uni_numeric)
ggplot(numeric, aes(x = loan_term)) +
geom_histogram(fill = "blue", color = "black") +
labs(title = paste("Distribution of loan_term"))
ggplot(numeric, aes(x = log(loan_term))) +
geom_histogram(fill = "blue", color = "black") +
labs(title = paste("Distribution of loan_term"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(rpart)
library(ranger)
library(baguette)
library(bonsai)
library(lightgbm)
library(xgboost)
library(keras)
library(kernlab)
tidymodels_prefer()
train <- read_csv("clean_train.csv")
test <- read_csv("test2.csv")
factor_conversion <- function(feat) {
if (n_distinct(feat) <= 20) {
feat <- as.factor(feat)
}
return(feat)
}
train <- train %>%
mutate(across(everything(), factor_conversion))
test <- test %>%
mutate(across(everything(), factor_conversion))
# V-Folds CV
set.seed(2023)
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 3, strata = action_taken)
# V-Folds CV
set.seed(2023)
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 4, strata = action_taken)
# Preprocessing
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(rpart)
library(baguette)
library(bonsai)
library(lightgbm)
tidymodels_prefer()
train <- read_csv("clean_train.csv")
test <- read_csv("test2.csv")
factor_conversion <- function(feat) {
if (n_distinct(feat) <= 20) {
feat <- as.factor(feat)
}
return(feat)
}
train <- train %>%
mutate(across(everything(), factor_conversion))
test <- test %>%
mutate(across(everything(), factor_conversion))
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 3, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
mlp_spec <- mlp(
epochs = 45,
hidden_units = 8,
penalty = tune(),
activation = "softmax"
) %>%
set_engine("keras") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 3, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- mlp(
epochs = 45,
hidden_units = 8,
penalty = tune(),
activation = "softmax"
) %>%
set_engine("keras") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
grid <- grid_random(parameters(spec), size = 10)
tuned_wfl <- wfl %>%
tune_grid(resamples = folds,
grid = grid,
control = control_grid(verbose = TRUE))
show_notes(.Last.tune.result)
library(tidyverse)
library(tidymodels)
library(rpart)
library(baguette)
library(bonsai)
library(lightgbm)
library(keras)
tidymodels_prefer()
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 3, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- mlp(
epochs = 45,
hidden_units = 8,
penalty = tune(),
activation = "softmax"
) %>%
set_engine("keras") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
library(tidyverse)
library(tidymodels)
library(rpart)
library(baguette)
library(bonsai)
library(lightgbm)
library(keras)
tidymodels_prefer()
train <- read_csv("clean_train.csv")
test <- read_csv("test2.csv")
factor_conversion <- function(feat) {
if (n_distinct(feat) <= 20) {
feat <- as.factor(feat)
}
return(feat)
}
train <- train %>%
mutate(across(everything(), factor_conversion))
test <- test %>%
mutate(across(everything(), factor_conversion))
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 3, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- mlp(
epochs = 45,
hidden_units = 8,
penalty = tune(),
activation = "softmax"
) %>%
set_engine("keras") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
grid <- grid_random(parameters(spec), size = 10)
tuned_wfl <- wfl %>%
tune_grid(resamples = folds,
grid = grid,
control = control_grid(verbose = TRUE))
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train_eval, v = 3, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
# spec <- decision_tree(
#     tree_depth = tune(),
#     cost_complexity = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- parsnip::rand_forest(
trees = 888,
min_n = 39
) %>%
set_engine("ranger") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
library(tidyverse)
library(tidymodels)
library(rpart)
library(baguette)
library(bonsai)
library(lightgbm)
library(keras)
tidymodels_prefer()
train <- read_csv("clean_train.csv")
test <- read_csv("test2.csv")
factor_conversion <- function(feat) {
if (n_distinct(feat) <= 20) {
feat <- as.factor(feat)
}
return(feat)
}
train <- train %>%
mutate(across(everything(), factor_conversion))
test <- test %>%
mutate(across(everything(), factor_conversion))
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train, v = 5, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
# spec <- decision_tree(
#     tree_depth = tune(),
#     cost_complexity = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- parsnip::rand_forest(
trees = 888,
min_n = 39
) %>%
set_engine("ranger") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train, v = 5, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
# spec <- decision_tree(
#     tree_depth = tune(),
#     cost_complexity = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- parsnip::rand_forest(
trees = 888,
min_n = 39
) %>%
set_engine("ranger") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
train_split <- initial_split(train, prop = 0.5, strata = action_taken)
train_eval <- train_split %>% training()
folds <- vfold_cv(data = train, v = 5, strata = action_taken)
# spec <- logistic_reg(penalty = 0.1) %>%
#   set_engine("glmnet") %>%
#   set_mode("classification")
# spec <- decision_tree() %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- bag_tree(
#     tree_depth = 12,
#     min_n = 6,
#     cost_complexity = 8.095966e-08
#   ) %>%
#   set_engine("rpart") %>%
#   set_mode("classification")
# spec <- boost_tree(
#     tree_depth = tune(),
#     trees = tune(),
#     learn_rate = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
# spec <- decision_tree(
#     tree_depth = tune(),
#     cost_complexity = tune(),
#     min_n = tune()
#   ) %>%
#   set_engine("lightgbm") %>%
#   set_mode("classification")
spec <- parsnip::rand_forest(
trees = 888,
min_n = 39
) %>%
set_engine("ranger") %>%
set_mode("classification")
rec <- recipe(action_taken ~ ., data = train_eval) %>%
step_mutate(state = factor(state)) %>%
step_mutate(state = if_else(state == "PR", NA, state)) %>%
step_impute_mean(all_numeric_predictors()) %>%
step_impute_mode(all_nominal_predictors()) %>%
step_log(loan_amount, income, property_value, offset = 1) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
wfl <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
eval_wfl <- wfl %>%
fit_resamples(resamples = folds, control = control_grid(verbose = TRUE))
